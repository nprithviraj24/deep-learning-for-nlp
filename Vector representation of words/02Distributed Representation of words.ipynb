{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed representation of Words\n",
    "\n",
    "#### [Distributed semantics](https://en.wikipedia.org/wiki/Distributional_semantics) \n",
    "theoretically it states that we can analyze the use of words in language to deduce their meaning. Briefly, it derives from the concept called \"Distributional Hypothesis\" where the <i> linguistic items with similar distributions have similar meanings.</i>\n",
    "\n",
    "The <b>distributional hypothesis</b> in linguistics is derived from the semantic theory of language usage, i.e. words that are used and occur in the same contexts tend to purport similar meanings.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Co-occurence matrix\n",
    "It is matrix of terms × terms which captures the number of times a term appears in the context of another term is created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0 0 1 0 2 1 0 0 0 1 1 1 0 0 0 1 0 1 0]\n",
      " [1 0 0 1 0 0 1 0 2 1 0 0 0 1 1 1 0 0 0 1 0 1 0]\n",
      " [0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0]\n",
      " [1 1 0 0 0 0 1 0 2 1 0 0 0 1 1 1 0 0 0 1 0 1 0]\n",
      " [0 0 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0]\n",
      " [1 1 1 1 1 1 0 1 4 1 1 1 1 1 1 1 1 1 1 2 1 1 1]\n",
      " [0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1]\n",
      " [2 2 1 2 1 1 4 1 0 2 1 1 1 2 2 2 1 1 1 3 1 2 1]\n",
      " [1 1 0 1 0 0 1 0 2 0 0 0 0 1 1 1 0 0 0 1 0 1 0]\n",
      " [0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1]\n",
      " [0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1]\n",
      " [0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [1 1 0 1 0 0 1 0 2 1 0 0 0 0 1 1 0 0 0 1 0 1 0]\n",
      " [1 1 0 1 0 0 1 0 2 1 0 0 0 1 0 1 0 0 0 1 0 1 0]\n",
      " [1 1 0 1 0 0 1 0 2 1 0 0 0 1 1 0 0 0 0 1 0 1 0]\n",
      " [0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 1 0 1 0 1]\n",
      " [0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 0 1 0 1]\n",
      " [0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 1 0 1]\n",
      " [1 1 1 1 1 1 2 0 3 1 0 0 1 1 1 1 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1 1 1 0 0 0 1]\n",
      " [1 1 0 1 0 0 1 0 2 1 0 0 0 1 1 1 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "docs = ['Boston Celtics are leading in their conference.',\n",
    "        'LA Lakers have secured top spot in Western conference table.',\n",
    "        'Kobe and Lebron in 2010 were best players in their respective conference']\n",
    "count_model = CountVectorizer(ngram_range=(1,1)) # default unigram model\n",
    "X = count_model.fit_transform(docs)\n",
    "# X[X > 0] = 1 # run this line if you don't want extra within-text cooccurence (see below)\n",
    "Xc = (X.T * X) # this is co-occurrence matrix in sparse csr format\n",
    "Xc.setdiag(0) # sometimes you want to fill same word cooccurence to 0\n",
    "print(Xc.todense()) # print out matrix in dense format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is Co-occurrence matrix useful?\n",
    "\n",
    "### A blog post from [Chris Moody](https://multithreaded.stitchfix.com/blog/2017/10/18/stop-using-word2vec/) suggests that:\n",
    "We can directly factorize a co-occurrence matrix and get good word embeddings. In practice, we can follow these simple steps:\n",
    "- Compute the probability of occurrence of each word $p(x)$\n",
    "- Compute the probability of co-occurrence of each couple of words $p(x,y)$\n",
    "- Divide each co-occurrence probability by each word’s probability $p(x,y)/p(x)p(y)$\n",
    "- Apply the logarithm to the ratio: $ log[p(x,y)/p(x)p(y)].$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
